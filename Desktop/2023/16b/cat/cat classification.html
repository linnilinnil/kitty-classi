<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>cat-classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="cat classification_files/libs/clipboard/clipboard.min.js"></script>
<script src="cat classification_files/libs/quarto-html/quarto.js"></script>
<script src="cat classification_files/libs/quarto-html/popper.min.js"></script>
<script src="cat classification_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="cat classification_files/libs/quarto-html/anchor.min.js"></script>
<link href="cat classification_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="cat classification_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="cat classification_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="cat classification_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="cat classification_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="libraries" class="level1">
<h1>Libraries</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> utils </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="8b626efc-8359-4392-818a-863ec89ef180">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tf.test.gpu_device_name())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>/device:GPU:0</code></pre>
</div>
</div>
<div class="cell" data-outputid="2e4c394e-c990-44c6-8eff-88d57fe83630">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># location of data</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>_URL <span class="op">=</span> <span class="st">'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># download the data and extract it</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>path_to_zip <span class="op">=</span> utils.get_file(<span class="st">'cats_and_dogs.zip'</span>, origin<span class="op">=</span>_URL, extract<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># construct paths</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>PATH <span class="op">=</span> os.path.join(os.path.dirname(path_to_zip), <span class="st">'cats_and_dogs_filtered'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>train_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'train'</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>validation_dir <span class="op">=</span> os.path.join(PATH, <span class="st">'validation'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters for datasets</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>IMG_SIZE <span class="op">=</span> (<span class="dv">160</span>, <span class="dv">160</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co"># construct train and validation datasets </span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> utils.image_dataset_from_directory(train_dir,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                                                   shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>                                                   batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>                                                   image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> utils.image_dataset_from_directory(validation_dir,</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                                                        shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>                                                        batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>                                                        image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co"># construct the test dataset by taking every 5th observation out of the validation dataset</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>val_batches <span class="op">=</span> tf.data.experimental.cardinality(validation_dataset)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> validation_dataset.take(val_batches <span class="op">//</span> <span class="dv">5</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.skip(val_batches <span class="op">//</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
68606236/68606236 [==============================] - 0s 0us/step
Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>AUTOTUNE <span class="op">=</span> tf.data.AUTOTUNE</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>validation_dataset <span class="op">=</span> validation_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.prefetch(buffer_size<span class="op">=</span>AUTOTUNE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="dataset-visualization" class="level1">
<h1>Dataset visualization</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="db685d57-6776-4c6d-ee95-c5e158ed9996">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>t_dataset <span class="op">=</span> utils.image_dataset_from_directory(train_dir,</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>                                                   shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                                                   batch_size<span class="op">=</span>BATCH_SIZE,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                                                   image_size<span class="op">=</span>IMG_SIZE)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>t_dataset.class_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Found 2000 files belonging to 2 classes.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>['cats', 'dogs']</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> two_row(batch):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  class_names <span class="op">=</span> [<span class="st">'cats'</span>, <span class="st">'dogs'</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> images, labels <span class="kw">in</span> batch:</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    cnt_cat <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    cnt_dog <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> cnt_cat <span class="op">&lt;</span> <span class="dv">3</span> <span class="kw">or</span> cnt_dog <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> labels[i] <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> cnt_cat <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        ax[<span class="dv">0</span>,cnt_cat].imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        ax[<span class="dv">0</span>,cnt_cat].set_title(class_names[labels[i]])</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">"off"</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        cnt_cat <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>      <span class="cf">elif</span> labels[i] <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> cnt_dog <span class="op">&lt;</span> <span class="dv">3</span>:</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        ax[<span class="dv">1</span>,cnt_dog].imshow(images[i].numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        ax[<span class="dv">1</span>,cnt_dog].set_title(class_names[labels[i]])</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">"off"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        cnt_dog <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>      i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="52c8cd9c-868d-40be-da4c-b9f1254cc2c1">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>two_row(train_dataset.take(<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="cat%20classification_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="check-frequencies" class="level1">
<h1>Check frequencies</h1>
<div class="cell" data-outputid="6823ce3a-9140-4f64-db18-834a45bbbdb1">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>labels_iterator<span class="op">=</span> train_dataset.unbatch().<span class="bu">map</span>(<span class="kw">lambda</span> image, label: label).as_numpy_iterator()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.
Instructions for updating:
Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089</code></pre>
</div>
</div>
<div class="cell" data-outputid="963e3428-56b0-4a6a-c550-67837ed6617a">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dogs <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>cnt <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> lbl <span class="kw">in</span> labels_iterator:</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  dogs <span class="op">+=</span> lbl</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>  cnt <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"dog: "</span>,dogs<span class="op">/</span>cnt)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"cat: "</span>,(cnt <span class="op">-</span> dogs) <span class="op">/</span> cnt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>dog:  0.5
cat:  0.5</code></pre>
</div>
</div>
</section>
<section id="first-model-sequential-model" class="level1">
<h1>First model: Sequential model</h1>
<p>Create a tf.keras.Sequential model using some of the layers we’ve discussed in class. In each model, include at least two Conv2D layers, at least two MaxPooling2D layers, at least one Flatten layer, at least one Dense layer, and at least one Dropout layer. Train your model and plot the history of the accuracy on both the training and validation sets. Give your model the name model1.</p>
<p>To train a model on a Dataset, use syntax like this:</p>
<p>history = model1.fit(train_dataset, epochs=20, validation_data=validation</p>
<p>Here and in later parts of this assignment, training for 20 epochs with the Dataset settings described above should be sufficient.</p>
<p>You don’t have to show multiple models, but please do a few experiments to try to get the best validation accuracy you can. Briefly describe a few of the things you tried. Please make sure that you are able to consistently achieve at least 52% validation accuracy in this part (i.e.&nbsp;just a bit better than baseline).</p>
<p>In bold font, describe the validation accuracy of your model during training. You don’t have to be precise. For example, “the accuracy of my model stabilized between 65% and 70% during training.”</p>
<p>Then, compare that to the baseline. How much better did you do? Overfitting can be observed when the training accuracy is much higher than the validation accuracy. Do you observe overfitting in model1?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="2afc5522-9048-4554-f114-31a686a48597">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>train_dataset.take(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>&lt;TakeDataset element_spec=(TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="ab6f9e99-d97f-4e42-d6ea-4e5cd20166ea">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#one batch has a total of 32 images, </span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#the output is either dog/cat for each image, binary classification</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#from above, the shape of each input/img is 160,160,3 (height, width, rgb)</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> keras.Sequential([</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    keras.Input(shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>)),</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(filters <span class="op">=</span> <span class="dv">32</span>, kernel_size <span class="op">=</span> (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.1</span>),</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>,<span class="dv">3</span>), <span class="dv">1</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">16</span>, activation<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>model1.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 78, 78, 32)        2432      
                                                                 
 dropout (Dropout)           (None, 78, 78, 32)        0         
                                                                 
 max_pooling2d (MaxPooling2D  (None, 39, 39, 32)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 37, 37, 32)        9248      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 18, 18, 32)       0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 10368)             0         
                                                                 
 dense (Dense)               (None, 32)                331808    
                                                                 
 dense_1 (Dense)             (None, 16)                528       
                                                                 
=================================================================
Total params: 344,016
Trainable params: 344,016
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> <span class="st">'adam'</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#sparse_categorical_crossentropy: Used as a loss function </span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#for multi-class classification model where the output label is assigned integer value (0, 1, 2, 3…).</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> tf.keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">'accuracy'</span>]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">compile</span>(optimizer, loss, metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="16e08fb0-907e-4c11-997b-67e020c8e6a9">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model1.fit(train_dataset, </span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>                     validation_data<span class="op">=</span>validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50
63/63 [==============================] - 14s 53ms/step - loss: 9.0446 - accuracy: 0.4470 - val_loss: 0.7199 - val_accuracy: 0.5371
Epoch 2/50
63/63 [==============================] - 3s 49ms/step - loss: 0.6849 - accuracy: 0.5975 - val_loss: 0.6745 - val_accuracy: 0.6040
Epoch 3/50
63/63 [==============================] - 4s 60ms/step - loss: 0.6038 - accuracy: 0.6875 - val_loss: 0.6509 - val_accuracy: 0.6597
Epoch 4/50
63/63 [==============================] - 4s 53ms/step - loss: 0.5629 - accuracy: 0.7135 - val_loss: 0.6924 - val_accuracy: 0.6275
Epoch 5/50
63/63 [==============================] - 4s 54ms/step - loss: 0.4958 - accuracy: 0.7600 - val_loss: 0.6700 - val_accuracy: 0.6597
Epoch 6/50
63/63 [==============================] - 3s 49ms/step - loss: 0.4461 - accuracy: 0.7970 - val_loss: 0.7408 - val_accuracy: 0.6411
Epoch 7/50
63/63 [==============================] - 6s 91ms/step - loss: 0.4132 - accuracy: 0.8140 - val_loss: 0.7357 - val_accuracy: 0.6646
Epoch 8/50
63/63 [==============================] - 3s 48ms/step - loss: 0.3683 - accuracy: 0.8305 - val_loss: 0.8711 - val_accuracy: 0.6040
Epoch 9/50
63/63 [==============================] - 5s 72ms/step - loss: 0.3934 - accuracy: 0.8135 - val_loss: 0.8444 - val_accuracy: 0.6262
Epoch 10/50
63/63 [==============================] - 3s 48ms/step - loss: 0.3014 - accuracy: 0.8670 - val_loss: 0.8653 - val_accuracy: 0.6349
Epoch 11/50
63/63 [==============================] - 3s 48ms/step - loss: 0.2654 - accuracy: 0.8865 - val_loss: 0.8746 - val_accuracy: 0.6522
Epoch 12/50
63/63 [==============================] - 5s 80ms/step - loss: 0.2195 - accuracy: 0.9130 - val_loss: 1.1526 - val_accuracy: 0.6262
Epoch 13/50
63/63 [==============================] - 5s 77ms/step - loss: 0.2017 - accuracy: 0.9210 - val_loss: 1.0514 - val_accuracy: 0.6448
Epoch 14/50
63/63 [==============================] - 6s 95ms/step - loss: 0.1705 - accuracy: 0.9330 - val_loss: 1.1487 - val_accuracy: 0.6361
Epoch 15/50
63/63 [==============================] - 3s 48ms/step - loss: 0.1574 - accuracy: 0.9390 - val_loss: 1.2391 - val_accuracy: 0.6460
Epoch 16/50
63/63 [==============================] - 3s 48ms/step - loss: 0.1482 - accuracy: 0.9415 - val_loss: 1.3938 - val_accuracy: 0.6448
Epoch 17/50
63/63 [==============================] - 4s 67ms/step - loss: 0.1119 - accuracy: 0.9560 - val_loss: 1.5561 - val_accuracy: 0.6176
Epoch 18/50
63/63 [==============================] - 4s 53ms/step - loss: 0.1389 - accuracy: 0.9465 - val_loss: 1.5458 - val_accuracy: 0.6361
Epoch 19/50
63/63 [==============================] - 3s 49ms/step - loss: 0.1691 - accuracy: 0.9330 - val_loss: 1.5418 - val_accuracy: 0.6213
Epoch 20/50
63/63 [==============================] - 4s 59ms/step - loss: 0.1459 - accuracy: 0.9485 - val_loss: 1.6921 - val_accuracy: 0.6349
Epoch 21/50
63/63 [==============================] - 3s 48ms/step - loss: 0.1121 - accuracy: 0.9585 - val_loss: 1.7612 - val_accuracy: 0.6411
Epoch 22/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0805 - accuracy: 0.9720 - val_loss: 1.8149 - val_accuracy: 0.6250
Epoch 23/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0809 - accuracy: 0.9695 - val_loss: 2.0050 - val_accuracy: 0.6213
Epoch 24/50
63/63 [==============================] - 5s 74ms/step - loss: 0.0734 - accuracy: 0.9730 - val_loss: 1.9849 - val_accuracy: 0.6262
Epoch 25/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0617 - accuracy: 0.9780 - val_loss: 2.0790 - val_accuracy: 0.6139
Epoch 26/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0718 - accuracy: 0.9735 - val_loss: 2.0649 - val_accuracy: 0.6337
Epoch 27/50
63/63 [==============================] - 5s 75ms/step - loss: 0.0691 - accuracy: 0.9700 - val_loss: 2.1949 - val_accuracy: 0.6151
Epoch 28/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 2.0743 - val_accuracy: 0.6337
Epoch 29/50
63/63 [==============================] - 6s 87ms/step - loss: 0.1642 - accuracy: 0.9455 - val_loss: 2.2722 - val_accuracy: 0.6386
Epoch 30/50
63/63 [==============================] - 6s 92ms/step - loss: 0.1576 - accuracy: 0.9545 - val_loss: 1.8130 - val_accuracy: 0.6262
Epoch 31/50
63/63 [==============================] - 4s 53ms/step - loss: 0.0969 - accuracy: 0.9645 - val_loss: 2.4169 - val_accuracy: 0.6188
Epoch 32/50
63/63 [==============================] - 6s 82ms/step - loss: 0.0848 - accuracy: 0.9710 - val_loss: 2.3626 - val_accuracy: 0.6213
Epoch 33/50
63/63 [==============================] - 3s 47ms/step - loss: 0.0801 - accuracy: 0.9635 - val_loss: 2.3931 - val_accuracy: 0.6399
Epoch 34/50
63/63 [==============================] - 5s 75ms/step - loss: 0.1094 - accuracy: 0.9535 - val_loss: 2.6719 - val_accuracy: 0.6188
Epoch 35/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0587 - accuracy: 0.9790 - val_loss: 2.6054 - val_accuracy: 0.6423
Epoch 36/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 2.5520 - val_accuracy: 0.6324
Epoch 37/50
63/63 [==============================] - 3s 50ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 2.6287 - val_accuracy: 0.6312
Epoch 38/50
63/63 [==============================] - 5s 71ms/step - loss: 0.0432 - accuracy: 0.9850 - val_loss: 2.7542 - val_accuracy: 0.6423
Epoch 39/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 2.8145 - val_accuracy: 0.6361
Epoch 40/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0372 - accuracy: 0.9895 - val_loss: 3.0052 - val_accuracy: 0.6040
Epoch 41/50
63/63 [==============================] - 5s 75ms/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 2.9740 - val_accuracy: 0.6386
Epoch 42/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0786 - accuracy: 0.9755 - val_loss: 2.9864 - val_accuracy: 0.6176
Epoch 43/50
63/63 [==============================] - 3s 48ms/step - loss: 0.1579 - accuracy: 0.9620 - val_loss: 3.0914 - val_accuracy: 0.6077
Epoch 44/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0814 - accuracy: 0.9675 - val_loss: 2.8460 - val_accuracy: 0.6386
Epoch 45/50
63/63 [==============================] - 5s 76ms/step - loss: 0.1028 - accuracy: 0.9655 - val_loss: 3.1745 - val_accuracy: 0.6250
Epoch 46/50
63/63 [==============================] - 3s 48ms/step - loss: 0.1022 - accuracy: 0.9725 - val_loss: 3.0819 - val_accuracy: 0.6126
Epoch 47/50
63/63 [==============================] - 3s 49ms/step - loss: 0.0784 - accuracy: 0.9760 - val_loss: 3.2478 - val_accuracy: 0.6213
Epoch 48/50
63/63 [==============================] - 5s 74ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 3.0277 - val_accuracy: 0.6312
Epoch 49/50
63/63 [==============================] - 3s 48ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 3.4703 - val_accuracy: 0.6176
Epoch 50/50
63/63 [==============================] - 3s 47ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 3.4245 - val_accuracy: 0.6287</code></pre>
</div>
</div>
<p>The validation accuracy of my model stabilized <strong>somewhere between 61% and 63%</strong> during training, more than <strong>10% improvement comparing to the baseline.</strong> However, the training accuracy is as high as 98.90%, an evidence for <strong>overfitting</strong>.</p>
</section>
<section id="second-model-with-data-augmentation" class="level1">
<h1>Second model: With data augmentation</h1>
<section id="random-flip" class="level2">
<h2 class="anchored" data-anchor-id="random-flip">Random Flip</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#input: 3D (unbatched) or 4D (batched) tensor with shape: </span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#(..., height, width, channels), in "channels_last" format.</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#output: same</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>r_flip <span class="op">=</span> tf.keras.layers.RandomFlip(</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"horizontal_and_vertical"</span>, seed<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="5e385a86-a189-49fc-d19b-967248638ed2">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> train_dataset.take(<span class="dv">1</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img,labl <span class="kw">in</span> batch:</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  pic <span class="op">=</span> img[<span class="dv">0</span>]</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(r_flip(pic).numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax[0,i].set_title()</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="cat%20classification_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="random-rotate" class="level2">
<h2 class="anchored" data-anchor-id="random-rotate">Random Rotate</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">## rotate</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>r_rotate <span class="op">=</span> tf.keras.layers.RandomRotation(</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">#factor (rotation angle range, unit in percent of 2 pi)</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    factor <span class="op">=</span> (<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    fill_mode<span class="op">=</span><span class="st">"reflect"</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    interpolation<span class="op">=</span><span class="st">"bilinear"</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    fill_value<span class="op">=</span><span class="fl">0.0</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="393835ef-0c99-4628-e2e9-b9a5d134c0f7">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> train_dataset.take(<span class="dv">1</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img,labl <span class="kw">in</span> batch:</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  pic <span class="op">=</span> img[<span class="dv">0</span>]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    ax[i].imshow(r_rotate(pic).numpy().astype(<span class="st">"uint8"</span>))</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#ax[0,i].set_title()</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">"off"</span>)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="cat%20classification_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="782b4531-d51d-48bd-f9d9-0c3d33018b84">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#adding preprocessing: random flip and random rotate</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> keras.Sequential([</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    keras.Input(shape<span class="op">=</span>(<span class="dv">160</span>,<span class="dv">160</span>,<span class="dv">3</span>)),</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    r_flip,</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    r_rotate,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(filters <span class="op">=</span> <span class="dv">32</span>, kernel_size <span class="op">=</span> (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.1</span>),</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>,<span class="dv">3</span>), <span class="dv">1</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">16</span>, activation<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>model2.build()</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>model2.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_3"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 random_flip (RandomFlip)    (None, 160, 160, 3)       0         
                                                                 
 random_rotation (RandomRota  (None, 160, 160, 3)      0         
 tion)                                                           
                                                                 
 conv2d_6 (Conv2D)           (None, 78, 78, 32)        2432      
                                                                 
 dropout_3 (Dropout)         (None, 78, 78, 32)        0         
                                                                 
 max_pooling2d_6 (MaxPooling  (None, 39, 39, 32)       0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 37, 37, 32)        9248      
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 18, 18, 32)       0         
 2D)                                                             
                                                                 
 flatten_3 (Flatten)         (None, 10368)             0         
                                                                 
 dense_6 (Dense)             (None, 32)                331808    
                                                                 
 dense_7 (Dense)             (None, 16)                528       
                                                                 
=================================================================
Total params: 344,016
Trainable params: 344,016
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model2.<span class="bu">compile</span>(optimizer, loss, metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="5b1688df-4341-4a9b-8b3e-6b4a727a4c2f">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>history2 <span class="op">=</span> model2.fit(train_dataset, </span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>                     validation_data <span class="op">=</span> validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>63/63 [==============================] - 12s 136ms/step - loss: 4.0756 - accuracy: 0.4935 - val_loss: 0.7550 - val_accuracy: 0.5186
Epoch 2/50
63/63 [==============================] - 8s 122ms/step - loss: 0.7321 - accuracy: 0.5460 - val_loss: 0.7016 - val_accuracy: 0.5606
Epoch 3/50
63/63 [==============================] - 10s 148ms/step - loss: 0.7107 - accuracy: 0.5390 - val_loss: 0.7209 - val_accuracy: 0.5408
Epoch 4/50
63/63 [==============================] - 9s 143ms/step - loss: 0.7210 - accuracy: 0.5490 - val_loss: 0.6741 - val_accuracy: 0.5879
Epoch 5/50
63/63 [==============================] - 8s 117ms/step - loss: 0.6888 - accuracy: 0.5740 - val_loss: 0.6998 - val_accuracy: 0.5965
Epoch 6/50
63/63 [==============================] - 9s 140ms/step - loss: 0.6974 - accuracy: 0.5610 - val_loss: 0.6889 - val_accuracy: 0.5792
Epoch 7/50
63/63 [==============================] - 9s 142ms/step - loss: 0.6945 - accuracy: 0.5735 - val_loss: 0.6859 - val_accuracy: 0.5532
Epoch 8/50
63/63 [==============================] - 8s 122ms/step - loss: 0.6753 - accuracy: 0.5760 - val_loss: 0.6853 - val_accuracy: 0.5272
Epoch 9/50
63/63 [==============================] - 8s 127ms/step - loss: 0.6654 - accuracy: 0.5855 - val_loss: 0.6860 - val_accuracy: 0.5458
Epoch 10/50
63/63 [==============================] - 9s 141ms/step - loss: 0.6758 - accuracy: 0.5735 - val_loss: 0.6878 - val_accuracy: 0.5594
Epoch 11/50
63/63 [==============================] - 10s 152ms/step - loss: 0.6591 - accuracy: 0.6025 - val_loss: 0.6608 - val_accuracy: 0.5743
Epoch 12/50
63/63 [==============================] - 8s 116ms/step - loss: 0.6761 - accuracy: 0.5735 - val_loss: 0.6518 - val_accuracy: 0.6312
Epoch 13/50
63/63 [==============================] - 9s 141ms/step - loss: 0.7175 - accuracy: 0.5320 - val_loss: 0.8113 - val_accuracy: 0.5062
Epoch 14/50
63/63 [==============================] - 9s 146ms/step - loss: 0.6544 - accuracy: 0.6070 - val_loss: 0.6738 - val_accuracy: 0.5953
Epoch 15/50
63/63 [==============================] - 8s 116ms/step - loss: 0.6617 - accuracy: 0.5960 - val_loss: 0.6667 - val_accuracy: 0.6139
Epoch 16/50
63/63 [==============================] - 9s 141ms/step - loss: 0.6601 - accuracy: 0.6035 - val_loss: 0.6790 - val_accuracy: 0.6077
Epoch 17/50
63/63 [==============================] - 8s 122ms/step - loss: 0.6619 - accuracy: 0.5950 - val_loss: 0.7183 - val_accuracy: 0.5767
Epoch 18/50
63/63 [==============================] - 8s 116ms/step - loss: 0.6759 - accuracy: 0.6170 - val_loss: 0.6822 - val_accuracy: 0.5606
Epoch 19/50
63/63 [==============================] - 9s 133ms/step - loss: 0.6648 - accuracy: 0.5965 - val_loss: 0.7517 - val_accuracy: 0.5136
Epoch 20/50
63/63 [==============================] - 10s 162ms/step - loss: 0.6946 - accuracy: 0.5550 - val_loss: 0.6791 - val_accuracy: 0.5866
Epoch 21/50
63/63 [==============================] - 11s 178ms/step - loss: 0.6878 - accuracy: 0.5665 - val_loss: 0.6356 - val_accuracy: 0.6423
Epoch 22/50
63/63 [==============================] - 10s 158ms/step - loss: 0.6421 - accuracy: 0.6205 - val_loss: 0.6380 - val_accuracy: 0.6250
Epoch 23/50
63/63 [==============================] - 12s 185ms/step - loss: 0.6404 - accuracy: 0.6225 - val_loss: 0.6903 - val_accuracy: 0.5668
Epoch 24/50
63/63 [==============================] - 9s 144ms/step - loss: 0.6565 - accuracy: 0.6205 - val_loss: 0.6455 - val_accuracy: 0.6200
Epoch 25/50
63/63 [==============================] - 9s 133ms/step - loss: 0.6473 - accuracy: 0.6370 - val_loss: 0.6772 - val_accuracy: 0.6114
Epoch 26/50
63/63 [==============================] - 11s 180ms/step - loss: 0.6733 - accuracy: 0.5985 - val_loss: 0.6580 - val_accuracy: 0.6114
Epoch 27/50
63/63 [==============================] - 11s 161ms/step - loss: 0.6459 - accuracy: 0.6315 - val_loss: 0.6503 - val_accuracy: 0.6188
Epoch 28/50
63/63 [==============================] - 13s 200ms/step - loss: 0.6500 - accuracy: 0.6195 - val_loss: 0.6428 - val_accuracy: 0.6312
Epoch 29/50
63/63 [==============================] - 8s 122ms/step - loss: 0.6315 - accuracy: 0.6255 - val_loss: 0.6448 - val_accuracy: 0.6485
Epoch 30/50
63/63 [==============================] - 15s 227ms/step - loss: 0.6568 - accuracy: 0.6200 - val_loss: 0.6090 - val_accuracy: 0.6832
Epoch 31/50
63/63 [==============================] - 10s 146ms/step - loss: 0.6267 - accuracy: 0.6585 - val_loss: 0.6694 - val_accuracy: 0.5928
Epoch 32/50
63/63 [==============================] - 8s 120ms/step - loss: 0.6230 - accuracy: 0.6470 - val_loss: 0.6386 - val_accuracy: 0.6498
Epoch 33/50
63/63 [==============================] - 9s 142ms/step - loss: 0.6318 - accuracy: 0.6435 - val_loss: 0.6334 - val_accuracy: 0.6572
Epoch 34/50
63/63 [==============================] - 10s 151ms/step - loss: 0.6155 - accuracy: 0.6720 - val_loss: 0.6435 - val_accuracy: 0.6485
Epoch 35/50
63/63 [==============================] - 8s 118ms/step - loss: 0.6209 - accuracy: 0.6605 - val_loss: 0.6295 - val_accuracy: 0.6522
Epoch 36/50
63/63 [==============================] - 9s 132ms/step - loss: 0.6013 - accuracy: 0.6655 - val_loss: 0.6611 - val_accuracy: 0.6535
Epoch 37/50
63/63 [==============================] - 9s 144ms/step - loss: 0.6228 - accuracy: 0.6550 - val_loss: 0.6374 - val_accuracy: 0.6473
Epoch 38/50
63/63 [==============================] - 8s 119ms/step - loss: 0.6080 - accuracy: 0.6635 - val_loss: 1.1070 - val_accuracy: 0.5285
Epoch 39/50
63/63 [==============================] - 8s 120ms/step - loss: 0.6583 - accuracy: 0.6095 - val_loss: 0.6477 - val_accuracy: 0.6386
Epoch 40/50
63/63 [==============================] - 10s 154ms/step - loss: 0.6965 - accuracy: 0.5855 - val_loss: 0.7324 - val_accuracy: 0.5396
Epoch 41/50
63/63 [==============================] - 11s 164ms/step - loss: 0.7275 - accuracy: 0.5770 - val_loss: 0.7071 - val_accuracy: 0.5557
Epoch 42/50
63/63 [==============================] - 9s 146ms/step - loss: 0.6915 - accuracy: 0.5775 - val_loss: 0.6913 - val_accuracy: 0.5458
Epoch 43/50
63/63 [==============================] - 8s 121ms/step - loss: 0.6767 - accuracy: 0.5715 - val_loss: 0.6833 - val_accuracy: 0.5866
Epoch 44/50
63/63 [==============================] - 9s 145ms/step - loss: 0.6881 - accuracy: 0.5560 - val_loss: 0.6887 - val_accuracy: 0.6027
Epoch 45/50
63/63 [==============================] - 11s 174ms/step - loss: 0.6501 - accuracy: 0.6280 - val_loss: 0.6613 - val_accuracy: 0.6213
Epoch 46/50
63/63 [==============================] - 8s 122ms/step - loss: 0.6586 - accuracy: 0.6075 - val_loss: 0.6697 - val_accuracy: 0.6238
Epoch 47/50
63/63 [==============================] - 11s 169ms/step - loss: 0.6692 - accuracy: 0.6160 - val_loss: 0.6544 - val_accuracy: 0.6200
Epoch 48/50
63/63 [==============================] - 8s 124ms/step - loss: 0.6299 - accuracy: 0.6465 - val_loss: 0.6437 - val_accuracy: 0.6436
Epoch 49/50
63/63 [==============================] - 8s 117ms/step - loss: 0.6260 - accuracy: 0.6500 - val_loss: 0.6142 - val_accuracy: 0.6770
Epoch 50/50
63/63 [==============================] - 9s 145ms/step - loss: 0.6195 - accuracy: 0.6555 - val_loss: 0.6257 - val_accuracy: 0.6522</code></pre>
</div>
</div>
<p>The model performance with data augmentation included is similar to the previous one with validation accuracy reaching somewhere <strong>between 62% and 67%</strong>, but <strong>without significant overfitting</strong> as the training accuracy is somehwere around 65% also.</p>
</section>
</section>
<section id="third-model-adding-more-data-preprocesing" class="level1">
<h1>Third model: adding more data preprocesing</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>(<span class="dv">160</span>, <span class="dv">160</span>, <span class="dv">3</span>))</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> tf.keras.applications.mobilenet_v2.preprocess_input(i)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>preprocessor <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [i], outputs <span class="op">=</span> [x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="39d40b3e-33a1-4f16-c07a-0c60db41294d">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#adding preprocessing: random flip and random rotate</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> keras.Sequential([</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    preprocessor,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    r_flip,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    r_rotate,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(filters <span class="op">=</span> <span class="dv">32</span>, kernel_size <span class="op">=</span> (<span class="dv">5</span>,<span class="dv">5</span>), strides<span class="op">=</span>(<span class="dv">2</span>,<span class="dv">2</span>), activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.1</span>),</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    layers.Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>,<span class="dv">3</span>), <span class="dv">1</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    layers.MaxPooling2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">16</span>, activation<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>model3.build()</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>model3.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_5"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 160, 160, 3)       0         
                                                                 
 random_flip (RandomFlip)    (None, 160, 160, 3)       0         
                                                                 
 random_rotation (RandomRota  (None, 160, 160, 3)      0         
 tion)                                                           
                                                                 
 conv2d_10 (Conv2D)          (None, 78, 78, 32)        2432      
                                                                 
 dropout_5 (Dropout)         (None, 78, 78, 32)        0         
                                                                 
 max_pooling2d_10 (MaxPoolin  (None, 39, 39, 32)       0         
 g2D)                                                            
                                                                 
 conv2d_11 (Conv2D)          (None, 37, 37, 32)        9248      
                                                                 
 max_pooling2d_11 (MaxPoolin  (None, 18, 18, 32)       0         
 g2D)                                                            
                                                                 
 flatten_5 (Flatten)         (None, 10368)             0         
                                                                 
 dense_10 (Dense)            (None, 32)                331808    
                                                                 
 dense_11 (Dense)            (None, 16)                528       
                                                                 
=================================================================
Total params: 344,016
Trainable params: 344,016
Non-trainable params: 0
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>model3.<span class="bu">compile</span>(optimizer, loss, metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="ed79eaac-b49c-4a9b-f5f7-a264ecb2f44f">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>history3 <span class="op">=</span> model3.fit(train_dataset, </span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>                     validation_data <span class="op">=</span> validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>63/63 [==============================] - 13s 140ms/step - loss: 0.7305 - accuracy: 0.5600 - val_loss: 0.6759 - val_accuracy: 0.5941
Epoch 2/50
63/63 [==============================] - 11s 179ms/step - loss: 0.6545 - accuracy: 0.6090 - val_loss: 0.6424 - val_accuracy: 0.6324
Epoch 3/50
63/63 [==============================] - 8s 124ms/step - loss: 0.6459 - accuracy: 0.6365 - val_loss: 0.6268 - val_accuracy: 0.6522
Epoch 4/50
63/63 [==============================] - 9s 132ms/step - loss: 0.6331 - accuracy: 0.6340 - val_loss: 0.6149 - val_accuracy: 0.6844
Epoch 5/50
63/63 [==============================] - 9s 147ms/step - loss: 0.6036 - accuracy: 0.6745 - val_loss: 0.5946 - val_accuracy: 0.6757
Epoch 6/50
63/63 [==============================] - 8s 121ms/step - loss: 0.5918 - accuracy: 0.6800 - val_loss: 0.5733 - val_accuracy: 0.6943
Epoch 7/50
63/63 [==============================] - 8s 118ms/step - loss: 0.5924 - accuracy: 0.6745 - val_loss: 0.6273 - val_accuracy: 0.6448
Epoch 8/50
63/63 [==============================] - 13s 192ms/step - loss: 0.5949 - accuracy: 0.6820 - val_loss: 0.6055 - val_accuracy: 0.6621
Epoch 9/50
63/63 [==============================] - 9s 145ms/step - loss: 0.5899 - accuracy: 0.6740 - val_loss: 0.6145 - val_accuracy: 0.6621
Epoch 10/50
63/63 [==============================] - 9s 145ms/step - loss: 0.5893 - accuracy: 0.6915 - val_loss: 0.5710 - val_accuracy: 0.6993
Epoch 11/50
63/63 [==============================] - 8s 119ms/step - loss: 0.5574 - accuracy: 0.7080 - val_loss: 0.5739 - val_accuracy: 0.6931
Epoch 12/50
63/63 [==============================] - 11s 169ms/step - loss: 0.5672 - accuracy: 0.6975 - val_loss: 0.5582 - val_accuracy: 0.6980
Epoch 13/50
63/63 [==============================] - 8s 120ms/step - loss: 0.5543 - accuracy: 0.7110 - val_loss: 0.5619 - val_accuracy: 0.6881
Epoch 14/50
63/63 [==============================] - 8s 119ms/step - loss: 0.5666 - accuracy: 0.6990 - val_loss: 0.5545 - val_accuracy: 0.7067
Epoch 15/50
63/63 [==============================] - 9s 145ms/step - loss: 0.5484 - accuracy: 0.7145 - val_loss: 0.5601 - val_accuracy: 0.7017
Epoch 16/50
63/63 [==============================] - 9s 146ms/step - loss: 0.5491 - accuracy: 0.7130 - val_loss: 0.5683 - val_accuracy: 0.7005
Epoch 17/50
63/63 [==============================] - 9s 139ms/step - loss: 0.5436 - accuracy: 0.7210 - val_loss: 0.5584 - val_accuracy: 0.7067
Epoch 18/50
63/63 [==============================] - 10s 159ms/step - loss: 0.5432 - accuracy: 0.7190 - val_loss: 0.5761 - val_accuracy: 0.7042
Epoch 19/50
63/63 [==============================] - 13s 209ms/step - loss: 0.5325 - accuracy: 0.7370 - val_loss: 0.5598 - val_accuracy: 0.7017
Epoch 20/50
63/63 [==============================] - 16s 241ms/step - loss: 0.5387 - accuracy: 0.7300 - val_loss: 0.5343 - val_accuracy: 0.7141
Epoch 21/50
63/63 [==============================] - 10s 141ms/step - loss: 0.5448 - accuracy: 0.7255 - val_loss: 0.6586 - val_accuracy: 0.6361
Epoch 22/50
63/63 [==============================] - 10s 154ms/step - loss: 0.5316 - accuracy: 0.7300 - val_loss: 0.5711 - val_accuracy: 0.7054
Epoch 23/50
63/63 [==============================] - 10s 153ms/step - loss: 0.5179 - accuracy: 0.7390 - val_loss: 0.5543 - val_accuracy: 0.7191
Epoch 24/50
63/63 [==============================] - 11s 179ms/step - loss: 0.5183 - accuracy: 0.7385 - val_loss: 0.5317 - val_accuracy: 0.7166
Epoch 25/50
63/63 [==============================] - 9s 142ms/step - loss: 0.5146 - accuracy: 0.7460 - val_loss: 0.5647 - val_accuracy: 0.7042
Epoch 26/50
63/63 [==============================] - 9s 143ms/step - loss: 0.5119 - accuracy: 0.7420 - val_loss: 0.5662 - val_accuracy: 0.7104
Epoch 27/50
63/63 [==============================] - 9s 146ms/step - loss: 0.4905 - accuracy: 0.7570 - val_loss: 0.6048 - val_accuracy: 0.7030
Epoch 28/50
63/63 [==============================] - 8s 117ms/step - loss: 0.5120 - accuracy: 0.7390 - val_loss: 0.5372 - val_accuracy: 0.7265
Epoch 29/50
63/63 [==============================] - 9s 144ms/step - loss: 0.4876 - accuracy: 0.7695 - val_loss: 0.5654 - val_accuracy: 0.7067
Epoch 30/50
63/63 [==============================] - 10s 149ms/step - loss: 0.5052 - accuracy: 0.7590 - val_loss: 0.5366 - val_accuracy: 0.7240
Epoch 31/50
63/63 [==============================] - 8s 117ms/step - loss: 0.4856 - accuracy: 0.7650 - val_loss: 0.5385 - val_accuracy: 0.7240
Epoch 32/50
63/63 [==============================] - 10s 148ms/step - loss: 0.4745 - accuracy: 0.7840 - val_loss: 0.5287 - val_accuracy: 0.7290
Epoch 33/50
63/63 [==============================] - 9s 147ms/step - loss: 0.4799 - accuracy: 0.7605 - val_loss: 0.5576 - val_accuracy: 0.7116
Epoch 34/50
63/63 [==============================] - 8s 118ms/step - loss: 0.4811 - accuracy: 0.7600 - val_loss: 0.5079 - val_accuracy: 0.7475
Epoch 35/50
63/63 [==============================] - 10s 149ms/step - loss: 0.4729 - accuracy: 0.7690 - val_loss: 0.5933 - val_accuracy: 0.7054
Epoch 36/50
63/63 [==============================] - 10s 155ms/step - loss: 0.4984 - accuracy: 0.7675 - val_loss: 0.5220 - val_accuracy: 0.7376
Epoch 37/50
63/63 [==============================] - 9s 132ms/step - loss: 0.4845 - accuracy: 0.7555 - val_loss: 0.5131 - val_accuracy: 0.7351
Epoch 38/50
63/63 [==============================] - 9s 143ms/step - loss: 0.4595 - accuracy: 0.7770 - val_loss: 0.5723 - val_accuracy: 0.7054
Epoch 39/50
63/63 [==============================] - 9s 143ms/step - loss: 0.4698 - accuracy: 0.7750 - val_loss: 0.5284 - val_accuracy: 0.7376
Epoch 40/50
63/63 [==============================] - 8s 119ms/step - loss: 0.4727 - accuracy: 0.7730 - val_loss: 0.5317 - val_accuracy: 0.7376
Epoch 41/50
63/63 [==============================] - 8s 126ms/step - loss: 0.4759 - accuracy: 0.7695 - val_loss: 0.5556 - val_accuracy: 0.7104
Epoch 42/50
63/63 [==============================] - 9s 139ms/step - loss: 0.4613 - accuracy: 0.7935 - val_loss: 0.5647 - val_accuracy: 0.7042
Epoch 43/50
63/63 [==============================] - 8s 127ms/step - loss: 0.4545 - accuracy: 0.7775 - val_loss: 0.5112 - val_accuracy: 0.7450
Epoch 44/50
63/63 [==============================] - 10s 147ms/step - loss: 0.4364 - accuracy: 0.7965 - val_loss: 0.5362 - val_accuracy: 0.7389
Epoch 45/50
63/63 [==============================] - 12s 173ms/step - loss: 0.4349 - accuracy: 0.7980 - val_loss: 0.5546 - val_accuracy: 0.7290
Epoch 46/50
63/63 [==============================] - 12s 191ms/step - loss: 0.4516 - accuracy: 0.7870 - val_loss: 0.5443 - val_accuracy: 0.7401
Epoch 47/50
63/63 [==============================] - 9s 145ms/step - loss: 0.4393 - accuracy: 0.7970 - val_loss: 0.5473 - val_accuracy: 0.7463
Epoch 48/50
63/63 [==============================] - 13s 190ms/step - loss: 0.4459 - accuracy: 0.7875 - val_loss: 0.5607 - val_accuracy: 0.7277
Epoch 49/50
63/63 [==============================] - 12s 194ms/step - loss: 0.4347 - accuracy: 0.7980 - val_loss: 0.5752 - val_accuracy: 0.7166
Epoch 50/50
63/63 [==============================] - 10s 150ms/step - loss: 0.4405 - accuracy: 0.7925 - val_loss: 0.5470 - val_accuracy: 0.7191</code></pre>
</div>
</div>
<p>Given the additional preprocessing layer that normalizes the RGB values between [-1,1] before the actual training, the validation accuracy stablized somewhere <strong>between 70% and 71% without significant overfitting</strong>.</p>
</section>
<section id="fourth-model-with-transfer-learning" class="level1">
<h1>Fourth Model: With transfer learning</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>IMG_SHAPE <span class="op">=</span> IMG_SIZE <span class="op">+</span> (<span class="dv">3</span>,)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> tf.keras.applications.MobileNetV2(input_shape<span class="op">=</span>IMG_SHAPE,</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>                                               include_top<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>                                               weights<span class="op">=</span><span class="st">'imagenet'</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> tf.keras.Input(shape<span class="op">=</span>IMG_SHAPE)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> base_model(i, training <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>base_model_layer <span class="op">=</span> tf.keras.Model(inputs <span class="op">=</span> [i], outputs <span class="op">=</span> [x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="6044c283-1388-4ac8-ff4f-01331e162c10">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co">#adding preprocessing: random flip and random rotate</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>model4 <span class="op">=</span> keras.Sequential([</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    preprocessor,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    r_flip,</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    r_rotate,</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>    base_model_layer,</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    layers.Dropout(<span class="fl">.1</span>),</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    layers.GlobalMaxPooling2D(),</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    layers.Flatten(),</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">32</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    layers.Dense(<span class="dv">2</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>model4.build()</span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>model4.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model: "sequential_10"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 model (Functional)          (None, 160, 160, 3)       0         
                                                                 
 random_flip (RandomFlip)    (None, 160, 160, 3)       0         
                                                                 
 random_rotation (RandomRota  (None, 160, 160, 3)      0         
 tion)                                                           
                                                                 
 model_2 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                 
 dropout_11 (Dropout)        (None, 5, 5, 1280)        0         
                                                                 
 global_max_pooling2d_4 (Glo  (None, 1280)             0         
 balMaxPooling2D)                                                
                                                                 
 flatten_10 (Flatten)        (None, 1280)              0         
                                                                 
 dense_22 (Dense)            (None, 32)                40992     
                                                                 
 dense_23 (Dense)            (None, 2)                 66        
                                                                 
=================================================================
Total params: 2,299,042
Trainable params: 41,058
Non-trainable params: 2,257,984
_________________________________________________________________</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>model4.<span class="bu">compile</span>(optimizer,loss,metrics)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="2fd48466-e070-4260-a73c-319edb8057e3">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>history4 <span class="op">=</span> model4.fit(train_dataset, </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>                     epochs<span class="op">=</span><span class="dv">50</span>, </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>                     validation_data <span class="op">=</span> validation_dataset)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 1/50</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.
/usr/local/lib/python3.8/dist-packages/keras/backend.py:5585: UserWarning: "`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?
  output, from_logits = _get_logits(
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>63/63 [==============================] - 19s 171ms/step - loss: 0.4589 - accuracy: 0.8075 - val_loss: 0.1331 - val_accuracy: 0.9505
Epoch 2/50
63/63 [==============================] - 9s 137ms/step - loss: 0.2380 - accuracy: 0.8970 - val_loss: 0.0928 - val_accuracy: 0.9703
Epoch 3/50
63/63 [==============================] - 9s 142ms/step - loss: 0.2126 - accuracy: 0.9065 - val_loss: 0.0833 - val_accuracy: 0.9740
Epoch 4/50
63/63 [==============================] - 10s 161ms/step - loss: 0.2054 - accuracy: 0.9155 - val_loss: 0.0818 - val_accuracy: 0.9740
Epoch 5/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1844 - accuracy: 0.9195 - val_loss: 0.0736 - val_accuracy: 0.9678
Epoch 6/50
63/63 [==============================] - 10s 144ms/step - loss: 0.1760 - accuracy: 0.9285 - val_loss: 0.0711 - val_accuracy: 0.9728
Epoch 7/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1777 - accuracy: 0.9290 - val_loss: 0.0645 - val_accuracy: 0.9752
Epoch 8/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1541 - accuracy: 0.9365 - val_loss: 0.0657 - val_accuracy: 0.9765
Epoch 9/50
63/63 [==============================] - 9s 136ms/step - loss: 0.1785 - accuracy: 0.9225 - val_loss: 0.0800 - val_accuracy: 0.9691
Epoch 10/50
63/63 [==============================] - 10s 143ms/step - loss: 0.1592 - accuracy: 0.9280 - val_loss: 0.0620 - val_accuracy: 0.9728
Epoch 11/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1492 - accuracy: 0.9380 - val_loss: 0.0894 - val_accuracy: 0.9653
Epoch 12/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1513 - accuracy: 0.9380 - val_loss: 0.0562 - val_accuracy: 0.9790
Epoch 13/50
63/63 [==============================] - 9s 136ms/step - loss: 0.1436 - accuracy: 0.9415 - val_loss: 0.0700 - val_accuracy: 0.9728
Epoch 14/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1561 - accuracy: 0.9360 - val_loss: 0.0716 - val_accuracy: 0.9678
Epoch 15/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1421 - accuracy: 0.9445 - val_loss: 0.0640 - val_accuracy: 0.9715
Epoch 16/50
63/63 [==============================] - 9s 144ms/step - loss: 0.1533 - accuracy: 0.9430 - val_loss: 0.0718 - val_accuracy: 0.9666
Epoch 17/50
63/63 [==============================] - 9s 136ms/step - loss: 0.1258 - accuracy: 0.9465 - val_loss: 0.0646 - val_accuracy: 0.9740
Epoch 18/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1524 - accuracy: 0.9435 - val_loss: 0.0740 - val_accuracy: 0.9691
Epoch 19/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1326 - accuracy: 0.9470 - val_loss: 0.0717 - val_accuracy: 0.9666
Epoch 20/50
63/63 [==============================] - 10s 154ms/step - loss: 0.1348 - accuracy: 0.9435 - val_loss: 0.0708 - val_accuracy: 0.9728
Epoch 21/50
63/63 [==============================] - 10s 161ms/step - loss: 0.1236 - accuracy: 0.9485 - val_loss: 0.0558 - val_accuracy: 0.9728
Epoch 22/50
63/63 [==============================] - 9s 136ms/step - loss: 0.1478 - accuracy: 0.9355 - val_loss: 0.0543 - val_accuracy: 0.9765
Epoch 23/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1343 - accuracy: 0.9465 - val_loss: 0.0633 - val_accuracy: 0.9752
Epoch 24/50
63/63 [==============================] - 10s 157ms/step - loss: 0.1097 - accuracy: 0.9540 - val_loss: 0.0619 - val_accuracy: 0.9790
Epoch 25/50
63/63 [==============================] - 9s 146ms/step - loss: 0.1158 - accuracy: 0.9525 - val_loss: 0.0714 - val_accuracy: 0.9728
Epoch 26/50
63/63 [==============================] - 9s 137ms/step - loss: 0.1198 - accuracy: 0.9490 - val_loss: 0.0744 - val_accuracy: 0.9703
Epoch 27/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1217 - accuracy: 0.9485 - val_loss: 0.0623 - val_accuracy: 0.9777
Epoch 28/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1345 - accuracy: 0.9460 - val_loss: 0.0599 - val_accuracy: 0.9728
Epoch 29/50
63/63 [==============================] - 10s 155ms/step - loss: 0.1053 - accuracy: 0.9570 - val_loss: 0.0609 - val_accuracy: 0.9740
Epoch 30/50
63/63 [==============================] - 9s 134ms/step - loss: 0.1421 - accuracy: 0.9415 - val_loss: 0.0816 - val_accuracy: 0.9678
Epoch 31/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1043 - accuracy: 0.9540 - val_loss: 0.0724 - val_accuracy: 0.9653
Epoch 32/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1303 - accuracy: 0.9520 - val_loss: 0.0612 - val_accuracy: 0.9740
Epoch 33/50
63/63 [==============================] - 9s 135ms/step - loss: 0.1066 - accuracy: 0.9600 - val_loss: 0.0716 - val_accuracy: 0.9678
Epoch 34/50
63/63 [==============================] - 10s 157ms/step - loss: 0.1045 - accuracy: 0.9565 - val_loss: 0.0577 - val_accuracy: 0.9752
Epoch 35/50
63/63 [==============================] - 10s 161ms/step - loss: 0.0946 - accuracy: 0.9610 - val_loss: 0.0550 - val_accuracy: 0.9777
Epoch 36/50
63/63 [==============================] - 9s 133ms/step - loss: 0.1040 - accuracy: 0.9565 - val_loss: 0.0604 - val_accuracy: 0.9765
Epoch 37/50
63/63 [==============================] - 10s 159ms/step - loss: 0.1001 - accuracy: 0.9595 - val_loss: 0.0606 - val_accuracy: 0.9752
Epoch 38/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1013 - accuracy: 0.9580 - val_loss: 0.0660 - val_accuracy: 0.9752
Epoch 39/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1027 - accuracy: 0.9615 - val_loss: 0.0625 - val_accuracy: 0.9765
Epoch 40/50
63/63 [==============================] - 9s 136ms/step - loss: 0.0997 - accuracy: 0.9625 - val_loss: 0.0550 - val_accuracy: 0.9777
Epoch 41/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1018 - accuracy: 0.9610 - val_loss: 0.0622 - val_accuracy: 0.9814
Epoch 42/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1016 - accuracy: 0.9570 - val_loss: 0.0549 - val_accuracy: 0.9790
Epoch 43/50
63/63 [==============================] - 9s 135ms/step - loss: 0.0981 - accuracy: 0.9625 - val_loss: 0.0678 - val_accuracy: 0.9765
Epoch 44/50
63/63 [==============================] - 9s 141ms/step - loss: 0.1051 - accuracy: 0.9555 - val_loss: 0.0724 - val_accuracy: 0.9740
Epoch 45/50
63/63 [==============================] - 10s 160ms/step - loss: 0.1125 - accuracy: 0.9510 - val_loss: 0.0825 - val_accuracy: 0.9691
Epoch 46/50
63/63 [==============================] - 10s 158ms/step - loss: 0.1122 - accuracy: 0.9590 - val_loss: 0.0705 - val_accuracy: 0.9765
Epoch 47/50
63/63 [==============================] - 9s 135ms/step - loss: 0.0926 - accuracy: 0.9605 - val_loss: 0.0541 - val_accuracy: 0.9765
Epoch 48/50
63/63 [==============================] - 10s 161ms/step - loss: 0.0815 - accuracy: 0.9630 - val_loss: 0.0647 - val_accuracy: 0.9790
Epoch 49/50
63/63 [==============================] - 10s 161ms/step - loss: 0.0965 - accuracy: 0.9655 - val_loss: 0.0597 - val_accuracy: 0.9777
Epoch 50/50
63/63 [==============================] - 9s 136ms/step - loss: 0.0869 - accuracy: 0.9665 - val_loss: 0.0670 - val_accuracy: 0.9777</code></pre>
</div>
</div>
<p>By incorporating a pretrained network and transfer the learning to our model, the final validation accuracy we reached is approximately <strong>97.8%</strong> with no evidence of overfitting as the train accuracy is somewhere around 96.7%.</p>
</section>
<section id="test-on-test-set" class="level1">
<h1>Test on test set</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>https://keras.io/api/models/model_training_apis/#predictonbatch-method</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>test_image <span class="op">=</span> []</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>test_label <span class="op">=</span> []</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> image, label <span class="kw">in</span> test_dataset:</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>  test_image.append(image.numpy())</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>  test_label.append(label.numpy())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>test_imge <span class="op">=</span> np.concatenate(test_image)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>test_label <span class="op">=</span> np.concatenate(test_label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="939a7fc1-a670-4448-bcf8-4df9f0834a5b">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>test_label[<span class="dv">0</span>] <span class="co">#dog is 1, cat is 0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="171">
<pre><code>0</code></pre>
</div>
</div>
<div class="cell" data-outputid="2cb260fc-2ced-41a7-d15b-a8f653b58fe2">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(test_imge[<span class="dv">0</span>].astype(<span class="st">"uint8"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="172">
<pre><code>&lt;matplotlib.image.AxesImage at 0x7f49f4283970&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="cat%20classification_files/figure-html/cell-38-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="a88232a0-0dc7-4a21-8701-182cc994f3c8">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> model4.predict(test_imge)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>prediction.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>6/6 [==============================] - 0s 34ms/step</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="176">
<pre><code>(192, 2)</code></pre>
</div>
</div>
<div class="cell" data-outputid="5fe38fbf-7d07-4599-f583-778b19716d85">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> np.argmax(prediction, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>pred.shape <span class="op">==</span> test_label.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-outputid="cc3f2fcd-32e8-4d60-f25c-37baa062e078">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test accuracy: "</span>,np.<span class="bu">sum</span>([pred <span class="op">==</span> test_label])<span class="op">/</span><span class="bu">len</span>(pred))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Test accuracy:  0.9895833333333334</code></pre>
</div>
</div>
<p>We reached a final classification accuracy of <strong>98.96%</strong> on the test dataset by using the fourth model which incorporated color normalization, random flip/rotate, and learning transfer.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>